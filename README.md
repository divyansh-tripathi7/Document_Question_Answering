# Document_Question_Answering
## Flow of Work
![image](https://github.com/vanshika230/Document_Question_Answering/assets/74042272/fd1b1031-bb2b-4cc9-8e97-a021385e2c85)
To generate responses to your questions, the application follows these steps:

PDF Loading: The app reads and extracts the text content from multiple PDF documents.

Text Chunking: The extracted text is divided into smaller, manageable chunks for effective processing.

Language Model: The application utilizes a language model to create vector representations (embeddings) of the text chunks.

Similarity Matching: When you pose a question, the app compares it to the text chunks and identifies the most semantically similar ones.

Response Generation: The selected text chunks are then passed to the language model, which generates a response based on the relevant content found in the PDFs.
## Introduction
In today's rapidly expanding digital landscape, the volume of data is growing exponentially. 
With each passing day, organizations accumulate vast amounts of information, causing 
valuable insights and critical knowledge to become buried within the depths of countless 
documents. Consequently, we find ourselves wasting precious time navigating through an 
endless sea of data in search of specific information. It is evident that we require a more 
innovative and efficient solution to address this challenge.
But what if there was a more creative and intuitive solution to this problem? Imagine being 
able to have a conversation with our own documentsâ€”a chat-like experience where we could 
ask questions and receive insightful answers. This intriguing concept is made possible by 
leveraging the capabilities of large language models.
Large language models are advanced deep-learning models that have been extensively trained 
to understand and generate text in a remarkably human-like manner. By extracting the text 
from our documents and feeding it into these models, we can effectively create a questionanswering system that transforms the way we interact with our data.
With the implementation of such a system, we can extract textual data from our documents 
and pose questions directly to them. The large language model, with its vast knowledge and 
linguistic prowess, can then provide intelligent and contextually appropriate answers. This 
transformative approach allows us to effortlessly access relevant information and derive 
insights simply by engaging in conversational exchanges with our own data.


